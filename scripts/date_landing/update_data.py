# scripts/update_data.py

import os
import sys
import argparse
import datetime
import pandas as pd
import subprocess
from tqdm import tqdm

# è·¯å¾„é€‚é…
current_dir = os.path.dirname(os.path.abspath(__file__))
# ä»å½“å‰æ–‡ä»¶ä½ç½® (scripts/date_landing) è¿”å›ä¸¤çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.data_source.datahub import DataHub
from src.utils.config import GLOBAL_CONFIG
from src.utils.io import read_parquet, save_parquet, ensure_dir
from src.utils.logger import get_logger

logger = get_logger()

class DataUpdater:
    def __init__(self):
        self.config = GLOBAL_CONFIG
        self.paths = self.config["paths"]
        self.datahub = DataHub()
        
        # ä»Šå¤©çš„æ—¥æœŸ
        self.today = datetime.datetime.now().strftime("%Y-%m-%d")
        
        # åŠ è½½æœ¬åœ°äº¤æ˜“æ—¥å† (ç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°)
        self.calendar_path = os.path.join(self.paths["data_meta"], "trade_calendar.parquet")
        self.trade_dates = []
        self._load_local_calendar()

    def _load_local_calendar(self):
        """åŠ è½½æœ¬åœ°æ—¥å†ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆå§‹åŒ–ä¸ºç©º"""
        if os.path.exists(self.calendar_path):
            df = read_parquet(self.calendar_path)
            self.trade_dates = pd.to_datetime(df["date"]).dt.date.tolist()
            self.trade_dates.sort()
        else:
            self.trade_dates = []

    def get_last_date(self, df: pd.DataFrame) -> str:
        """è·å– DataFrame ä¸­çš„æœ€åæ—¥æœŸ"""
        if df is None or df.empty or "date" not in df.columns:
            return None
        return df["date"].max().strftime("%Y-%m-%d")

    def get_next_date(self, date_str: str) -> str:
        """ç»™å®šæ—¥æœŸï¼Œè¿”å›ä¸‹ä¸€å¤©"""
        if not date_str:
            return self.config["data"]["start_date"]
        
        dt = datetime.datetime.strptime(date_str, "%Y-%m-%d")
        next_dt = dt + datetime.timedelta(days=1)
        return next_dt.strftime("%Y-%m-%d")

    # ==========================================
    # 1. æ›´æ–°äº¤æ˜“æ—¥å†
    # ==========================================
    def update_calendar(self):
        logger.info(">>> æ­¥éª¤ 1/3: æ£€æŸ¥å¹¶æ›´æ–°äº¤æ˜“æ—¥å†...")
        
        try:
            # è·å–èŒƒå›´ï¼šä»é…ç½®å¼€å§‹æ—¥æœŸ åˆ° æœªæ¥ä¸€å¹´
            start_date = self.config["data"]["start_date"]
            future_date = (datetime.datetime.now() + datetime.timedelta(days=365)).strftime("%Y-%m-%d")
            
            df_cal = self.datahub.get_trade_calendar(start_date, future_date)
            
            if not df_cal.empty:
                save_parquet(df_cal, self.calendar_path)
                # åˆ·æ–°å†…å­˜ä¸­çš„æ—¥å†
                self._load_local_calendar()
                logger.info(f"äº¤æ˜“æ—¥å†å·²æ›´æ–°ï¼Œæœ€æ–°æ—¥æœŸè¦†ç›–è‡³: {self.get_last_date(df_cal)}")
            else:
                logger.warning("äº¤æ˜“æ—¥å†æ¥å£æœªè¿”å›æ•°æ®ï¼Œè·³è¿‡æ›´æ–°ã€‚")
        except Exception as e:
            logger.error(f"æ›´æ–°äº¤æ˜“æ—¥å†å¤±è´¥: {e}")

    # ==========================================
    # 2. æ›´æ–°æŒ‡æ•°
    # ==========================================
    def update_index(self):
        index_code = self.config["preprocessing"]["labels"]["index_code"]
        logger.info(f">>> æ­¥éª¤ 2/3: æ›´æ–°åŸºå‡†æŒ‡æ•° ({index_code})...")
        
        file_name = f"index_{index_code.replace('.', '')}.parquet"
        file_path = os.path.join(self.paths["data_raw"], file_name)
        
        df_local = pd.DataFrame()
        start_fetch_date = self.config["data"]["start_date"]
        
        # 1. è¯»å–æœ¬åœ°
        if os.path.exists(file_path):
            df_local = read_parquet(file_path)
            last_date = self.get_last_date(df_local)
            if last_date:
                # å¦‚æœæœ¬åœ°æœ€æ–°æ—¥æœŸ >= ä»Šå¤©ï¼Œè¯´æ˜ä¸ç”¨æ›´æ–°
                if last_date >= self.today:
                    logger.info(f"æŒ‡æ•° {index_code} å·²æ˜¯æœ€æ–° ({last_date})ï¼Œæ— éœ€æ›´æ–°ã€‚")
                    return
                start_fetch_date = self.get_next_date(last_date)
        
        # 2. ä¸‹è½½å¢é‡
        logger.info(f"æ­£åœ¨ä¸‹è½½æŒ‡æ•°å¢é‡æ•°æ®: {start_fetch_date} -> {self.today}")
        df_new = self.datahub.fetch_index_price(index_code, start_date=start_fetch_date, end_date=self.today) 
        
        if not df_new.empty:
            df_new["date"] = pd.to_datetime(df_new["date"])
            
            # 3. åˆå¹¶
            if not df_local.empty:
                df_final = pd.concat([df_local, df_new], axis=0)
                df_final = df_final.drop_duplicates(subset=["date"]).sort_values("date")
            else:
                df_final = df_new
            
            save_parquet(df_final, file_path)
            logger.info(f"æŒ‡æ•°æ›´æ–°å®Œæˆï¼Œæ–°å¢ {len(df_new)} æ¡è®°å½•ã€‚")
        else:
            logger.info("æœªå‘ç°æ–°çš„æŒ‡æ•°äº¤æ˜“æ•°æ®æˆ–æ•°æ®ä¸‹è½½å¤±è´¥ã€‚")

    # ==========================================
    # 3. æ›´æ–°ä¸ªè‚¡
    # ==========================================
    def update_stocks(self):
        logger.info(">>> æ­¥éª¤ 3/3: å¢é‡æ›´æ–°ä¸ªè‚¡æ•°æ®...")
        
        meta_path = os.path.join(self.paths["data_meta"], "all_stocks_meta.parquet")
        if not os.path.exists(meta_path):
            logger.error("å…ƒæ•°æ®ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ init_stock_pool.py")
            return
            
        raw_dir = self.paths["data_raw"]
        # ä»…æ›´æ–° data/raw ä¸‹å·²æœ‰çš„æ–‡ä»¶
        existing_files = [f for f in os.listdir(raw_dir) if f.endswith(".parquet") and f[0].isdigit()]
        
        if not existing_files:
            logger.warning("data/raw ä¸‹æ²¡æœ‰ä»»ä½•è‚¡ç¥¨æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ download_data.py è¿›è¡Œé¦–æ¬¡ä¸‹è½½ã€‚")
            return
            
        update_count = 0
        skip_count = 0
        
        # è·å–æœ€æ–°çš„å¸‚åœºäº¤æ˜“æ—¥
        if self.trade_dates:
            market_last_date = self.trade_dates[-1] 
        else:
            market_last_date = datetime.date.today()

        pbar = tqdm(existing_files, desc="Updating Stocks")
        
        for file_name in pbar:
            symbol = file_name.replace(".parquet", "")
            file_path = os.path.join(raw_dir, file_name)
            
            try:
                # 1. è¯»å–æœ¬åœ°æœ€åä¸€è¡Œ
                df_local = read_parquet(file_path)
                last_date_str = self.get_last_date(df_local)
                
                if not last_date_str:
                    start_date = self.config["data"]["start_date"]
                else:
                    last_date = datetime.datetime.strptime(last_date_str, "%Y-%m-%d").date()
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯æœ€æ–°
                    if last_date >= market_last_date:
                        skip_count += 1
                        continue
                        
                    start_date = self.get_next_date(last_date_str)

                # ä¸ºäº†é˜²æ­¢ start_date > end_date æŠ¥é”™
                if start_date > self.today:
                    skip_count += 1
                    continue
                    
                df_new = self.datahub.fetch_price(symbol, start_date=start_date, end_date=self.today)
                
                if not df_new.empty:
                    # åˆå¹¶ä¸å»é‡
                    df_final = pd.concat([df_local, df_new], axis=0)
                    df_final = df_final.drop_duplicates(subset=["date"], keep="last")
                    df_final = df_final.sort_values("date").reset_index(drop=True)
                    
                    save_parquet(df_final, file_path)
                    update_count += 1
                else:
                    skip_count += 1
                    
                pbar.set_postfix({"Upd": update_count, "Skip": skip_count})
                
            except Exception as e:
                logger.error(f"æ›´æ–° {symbol} å¤±è´¥: {e}")
        
        logger.info(f"æ›´æ–°å®Œæˆã€‚å·²æ›´æ–°: {update_count}, è·³è¿‡(æ— éœ€æ›´æ–°/åœç‰Œ): {skip_count}")

def run_external_script(script_rel_path, step_name):
    """
    è°ƒç”¨å¤–éƒ¨ Python è„šæœ¬
    :param script_rel_path: ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è„šæœ¬è·¯å¾„ (å¦‚ scripts/analisis/clean_and_check.py)
    :param step_name: æ­¥éª¤åç§°
    """
    script_path = os.path.join(project_root, script_rel_path)
    
    logger.info("\n" + "="*60)
    logger.info(f"ğŸš€ æ­£åœ¨å¯åŠ¨: {step_name} ...")
    logger.info(f"   è„šæœ¬è·¯å¾„: {script_path}")
    logger.info("="*60)
    
    if not os.path.exists(script_path):
        logger.error(f"âŒ æ‰¾ä¸åˆ°è„šæœ¬æ–‡ä»¶: {script_path}")
        return False
        
    try:
        # ä½¿ç”¨å½“å‰ Python è§£é‡Šå™¨æ‰§è¡Œ
        cmd = [sys.executable, script_path]
        # cwd è®¾ç½®ä¸º project_root ç¡®ä¿è„šæœ¬å†…éƒ¨ç›¸å¯¹è·¯å¾„é€»è¾‘æ­£å¸¸
        result = subprocess.run(cmd, cwd=project_root)
        
        if result.returncode == 0:
            logger.info(f"âœ… {step_name} æ‰§è¡ŒæˆåŠŸã€‚")
            return True
        else:
            logger.error(f"âŒ {step_name} æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return False
    except Exception as e:
        logger.error(f"âŒ {step_name} å‘ç”Ÿå¼‚å¸¸: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description="å¢é‡æ›´æ–°æœ¬åœ°æ•°æ®å¹¶è¿è¡Œå…¨æµç¨‹")
    parser.parse_args()
    
    # === 1. æ›´æ–°æ•°æ® (Download) ===
    try:
        updater = DataUpdater()
        updater.update_calendar()
        updater.update_index()
        updater.update_stocks()
    except Exception as e:
        logger.error(f"æ•°æ®æ›´æ–°é˜¶æ®µå‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return

    # === 2. æ¸…æ´—æ•°æ® (Clean) ===
    # è„šæœ¬: scripts/analisis/clean_and_check.py
    if not run_external_script(os.path.join("scripts", "analisis", "clean_and_check.py"), "æ•°æ®æ¸…æ´— (Clean)"):
        logger.warning("æµç¨‹ä¸­æ–­ï¼šæ•°æ®æ¸…æ´—å¤±è´¥ã€‚")
        return

    # === 3. æ„å»ºç‰¹å¾ (Feature Engineering) ===
    # è„šæœ¬: scripts/feature_create/rebuild_features.py
    if not run_external_script(os.path.join("scripts", "feature_create", "rebuild_features.py"), "ç‰¹å¾å·¥ç¨‹ (Features)"):
        logger.warning("æµç¨‹ä¸­æ–­ï¼šç‰¹å¾æ„å»ºå¤±è´¥ã€‚")
        return

    # === 4. æ¯æ—¥æ¨è (Recommendation) ===
    # è„šæœ¬: scripts/back_test/run_recommendation.py
    # æ¨èæœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥ç”± config/main.yaml -> strategy.recommend_history_days æ§åˆ¶
    if not run_external_script(os.path.join("scripts", "back_test", "run_recommendation.py"), "ç­–ç•¥æ¨è (Recommendation)"):
        logger.warning("æµç¨‹ä¸­æ–­ï¼šæ¨èç”Ÿæˆå¤±è´¥ã€‚")
        return
    
    logger.info("\n" + "="*60)
    logger.info("ğŸ‰ğŸ‰ğŸ‰ æ¯æ—¥å…¨æµç¨‹ä»»åŠ¡é¡ºåˆ©å®Œæˆï¼è¯·æŸ¥çœ‹ reports ç›®å½•ä¸‹çš„æ¨èç»“æœã€‚")
    logger.info("="*60)

if __name__ == "__main__":
    main()
