# scripts/run_recommendation.py

import os
import sys
import pandas as pd
import datetime
import glob
import re

# è·¯å¾„é€‚é…
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.append(project_root)

from src.utils.config import GLOBAL_CONFIG
from src.utils.logger import get_logger
from src.utils.io import read_parquet
from src.model.xgb_model import XGBModelWrapper
from src.strategy.signal import TopKSignalStrategy

logger = get_logger()

def get_latest_model_path():
    """
    æ™ºèƒ½å¯»æ‰¾ data/models ä¸‹æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶
    æ”¯æŒè¯†åˆ«æ™®é€šè®­ç»ƒç›®å½•å’Œ WF (æ»šåŠ¨è®­ç»ƒ) ç›®å½•
    """
    models_dir = GLOBAL_CONFIG["paths"]["models"]
    if not os.path.exists(models_dir):
        return None, None
    
    # 1. è·å–æ‰€æœ‰å­ç›®å½•
    subdirs = [d for d in os.listdir(models_dir) if os.path.isdir(os.path.join(models_dir, d))]
    if not subdirs:
        return None, None

    # 2. è¾…åŠ©å‡½æ•°ï¼šè§£æç›®å½•åä¸­çš„æ—¶é—´æˆ³
    def parse_timestamp(dir_name):
        # ç§»é™¤å‰ç¼€ (å¦‚ "WF_")
        clean_name = dir_name.replace("WF_", "")
        # å°è¯•åŒ¹é… YYYYMMDD_HHMMSS æ ¼å¼
        try:
            return datetime.datetime.strptime(clean_name, "%Y%m%d_%H%M%S")
        except ValueError:
            # å¦‚æœæ ¼å¼ä¸å¯¹ï¼Œè¿”å›ä¸€ä¸ªæå°æ—¶é—´ï¼Œæ’åœ¨æœ€å
            return datetime.datetime.min

    # 3. æŒ‰æ—¶é—´å€’åºæ’åˆ— (æœ€æ–°çš„åœ¨å‰)
    subdirs.sort(key=parse_timestamp, reverse=True)
    latest_version = subdirs[0]
    version_dir = os.path.join(models_dir, latest_version)
    
    logger.info(f"é”å®šæœ€æ–°æ¨¡å‹ç‰ˆæœ¬ç›®å½•: {latest_version}")

    # 4. åœ¨ç›®å½•ä¸­å¯»æ‰¾æœ€ä½³æ¨¡å‹æ–‡ä»¶
    # æƒ…å†µ A: å•æ¬¡è®­ç»ƒçš„æ ‡å‡†æ¨¡å‹
    if os.path.exists(os.path.join(version_dir, "model.json")):
        return latest_version, os.path.join(version_dir, "model.json")
    
    # æƒ…å†µ B: æ»šåŠ¨è®­ç»ƒçš„å¹´åº¦æ¨¡å‹ (model_2024.json, model_2025.json ...)
    # æˆ‘ä»¬éœ€è¦æ‰¾åˆ°å¹´ä»½æœ€å¤§çš„é‚£ä¸ªï¼Œå› ä¸ºå®ƒåŒ…å«äº†æœ€æ–°çš„å¸‚åœºè§„å¾‹
    wf_models = glob.glob(os.path.join(version_dir, "model_*.json"))
    if wf_models:
        def extract_year(path):
            fname = os.path.basename(path)
            # æå–æ•°å­—éƒ¨åˆ†
            match = re.search(r"model_(\d+)\.json", fname)
            return int(match.group(1)) if match else 0
        
        # æ‰¾å¹´ä»½æœ€å¤§çš„
        best_model_path = max(wf_models, key=extract_year)
        best_year = extract_year(best_model_path)
        logger.info(f"æ£€æµ‹åˆ°æ»šåŠ¨è®­ç»ƒæ¨¡å‹é›†ï¼Œå·²è‡ªåŠ¨é€‰æ‹©æœ€æ–°å¹´ä»½: model_{best_year}.json")
        return latest_version, best_model_path

    return None, None

def load_latest_data():
    """åŠ è½½ç‰¹å¾æ•°æ®ï¼Œå¹¶æå–å‡ºã€æœ€æ–°ä¸€ä¸ªäº¤æ˜“æ—¥ã€‘çš„æ•°æ®"""
    data_path = os.path.join(GLOBAL_CONFIG["paths"]["data_processed"], "all_stocks.parquet")
    if not os.path.exists(data_path):
        logger.error(f"ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {data_path}ï¼Œè¯·å…ˆè¿è¡Œ rebuild_features.py")
        return None, None

    # è¯»å–æ•°æ® (å®ç›˜å¯ä¼˜åŒ–ä¸ºåªè¯»æœ€åçš„åˆ†åŒº)
    df = read_parquet(data_path)
    
    # è·å–æ•°æ®ä¸­æœ€æ–°çš„æ—¥æœŸ
    latest_date = df["date"].max()
    logger.info(f"æ•°æ®é›†ä¸­æœ€æ–°æ—¥æœŸä¸º: {latest_date}")
    
    # ç­›é€‰å‡ºæœ€æ–°è¿™ä¸€å¤©çš„æ•°æ®
    df_latest = df[df["date"] == latest_date].copy()
    
    # æå–ç‰¹å¾åˆ— (feat_ å¼€å¤´)
    feat_cols = [c for c in df_latest.columns if c.startswith("feat_")]
    
    return df_latest, feat_cols

def main():
    logger.info("=== å¯åŠ¨æ¯æ—¥æ¨èç³»ç»Ÿ (Daily Recommendation) ===")

    # 1. æ™ºèƒ½åŠ è½½æ¨¡å‹
    version, model_path = get_latest_model_path()
    if not model_path:
        logger.error("æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ run_walkforward.py æˆ– train_model.py")
        return
    
    logger.info(f"åŠ è½½æ¨¡å‹æ–‡ä»¶: {model_path}")
    model = XGBModelWrapper()
    model.load(model_path)
    
    # 2. åŠ è½½æœ€æ–°è¡Œæƒ…æ•°æ®
    df_latest, feat_cols = load_latest_data()
    if df_latest is None or df_latest.empty:
        logger.error("ä»Šæ—¥æ— æ•°æ®ï¼Œæ— æ³•æ¨èã€‚")
        return

    # 3. æ‰§è¡Œé¢„æµ‹
    logger.info(f"æ­£åœ¨å¯¹ {len(df_latest)} åªè‚¡ç¥¨è¿›è¡Œæ‰“åˆ†...")
    pred_scores = model.predict(df_latest[feat_cols])
    
    pred_df = df_latest[["date", "symbol"]].copy()
    pred_df["pred_score"] = pred_scores
    
    # =======================================================
    # 4. ç­–ç•¥ç­›é€‰ (è¯»å–æ¨èä¸“ç”¨ Top-K é…ç½®)
    # =======================================================
    
    # ä¼˜å…ˆè¯»å– recommend_top_kï¼Œå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ° top_k
    strat_cfg = GLOBAL_CONFIG["strategy"]
    rec_k = strat_cfg.get("recommend_top_k", strat_cfg.get("top_k", 5))
    
    logger.info(f"ç”Ÿæˆæ¨èåˆ—è¡¨é•¿åº¦: {rec_k} (å«å¤‡é€‰)")
    
    # å®ä¾‹åŒ–ç­–ç•¥æ—¶ä¼ å…¥ top_k
    # æ³¨æ„ï¼šéœ€ç¡®ä¿ src/strategy/signal.py çš„ __init__ å·²æ”¯æŒ top_k å‚æ•°
    strategy = TopKSignalStrategy(top_k=rec_k)
    recommend_df = strategy.generate(pred_df)
    
    # 5. è¾“å‡ºç»“æœ
    if recommend_df.empty:
        logger.warning("ç­–ç•¥ç­›é€‰åæ— è‚¡ç¥¨å…¥é€‰ (å¯èƒ½éƒ½è¢«é£æ§å‰”é™¤æˆ–åˆ†æ•°ä¸è¶³)ã€‚")
        logger.info("Top 5 åŸå§‹é¢„æµ‹å¾—åˆ† (æœªç»è¿‡æ»¤):")
        print(pred_df.sort_values("pred_score", ascending=False).head(5))
        return

    # è¡¥å……è‚¡ç¥¨åç§°ä»¥ä¾¿é˜…è¯»
    meta_path = os.path.join(GLOBAL_CONFIG["paths"]["data_meta"], "all_stocks_meta.parquet")
    if os.path.exists(meta_path):
        df_meta = read_parquet(meta_path)
        recommend_df = pd.merge(recommend_df, df_meta[["symbol", "name"]], on="symbol", how="left")
    
    # è¡¥å……é¢„æµ‹åˆ†
    recommend_df = pd.merge(recommend_df, pred_df[["symbol", "pred_score"]], on="symbol", how="left")
    
    # æ ¼å¼åŒ–è¾“å‡º
    print("\n" + "="*60)
    print(f"ğŸŒŸ {df_latest['date'].iloc[0].strftime('%Y-%m-%d')} æ¯æ—¥ç²¾é€‰æ¨è (Top {len(recommend_df)}) ğŸŒŸ")
    print("="*60)
    
    cols = ["symbol", "name", "pred_score", "weight"]
    print_cols = [c for c in cols if c in recommend_df.columns]
    
    print_df = recommend_df[print_cols].sort_values("pred_score", ascending=False).reset_index(drop=True)
    
    # å°è¯•ä½¿ç”¨ tabulate ç¾åŒ–è¾“å‡º
    try:
        print(print_df.to_markdown(index=True, floatfmt=".4f"))
    except:
        print(print_df)
    
    # ä¿å­˜ç»“æœ
    out_dir = os.path.join(GLOBAL_CONFIG["paths"]["reports"], "daily_picks")
    if not os.path.exists(out_dir):
        os.makedirs(out_dir)
    out_file = os.path.join(out_dir, f"picks_{version}_{df_latest['date'].iloc[0].strftime('%Y%m%d')}.csv")
    print_df.to_csv(out_file, index=False, encoding="utf-8-sig")
    print(f"\n[æ–‡ä»¶] æ¨èåˆ—è¡¨å·²ä¿å­˜è‡³: {out_file}")
    print("="*60)

if __name__ == "__main__":
    main()